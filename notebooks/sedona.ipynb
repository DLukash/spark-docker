{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52f6becb-4246-40bc-8983-3f365121d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "from geopandas import GeoDataFrame\n",
    "import pandas as pd\n",
    "from shapely import wkt\n",
    "from pyspark.sql.functions import broadcast, pandas_udf, PandasUDFType, udf, col\n",
    "from pyspark.sql.types import StringType\n",
    "from shapely.geometry import Point, Polygon\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "from sedona.utils.adapter import Adapter\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import KryoSerializer, SedonaKryoRegistrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947fa69",
   "metadata": {},
   "source": [
    "### Create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5e2d48-598c-4652-a1e5-2938fa383063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark = SparkSession.builder.master('spark://spark:7077').config(conf=conf).appName('OpenSky_app').getOrCreate()\n",
    "# os.environ['PYSPARK_PYTHON'] = \"./environment/bin/python\"\n",
    "# config(\"spark.archives\",\"pyspark_conda_env.tar.gz#environment\"). \\\n",
    "\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = \"/opt/conda/envs/venv36/bin/python\"\n",
    "spark = SparkSession.builder.master(\"spark://spark:7077\"). \\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName). \\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-python-adapter-3.0_2.12:1.0.0-incubating,'\n",
    "           'org.datasyslab:geotools-wrapper:geotools-24.0'). \\\n",
    "    appName('OpenSky_app'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0108a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f9a23",
   "metadata": {},
   "source": [
    "### Load states boundaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27a40ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/venv36/lib/python3.6/site-packages/geopandas/array.py:85: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  aout[:] = out\n",
      "/opt/conda/envs/venv36/lib/python3.6/site-packages/geopandas/array.py:85: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  aout[:] = out\n"
     ]
    }
   ],
   "source": [
    "#Load data from local file to geoDataFrame\n",
    "geo_admin_url = 'admin1-us.geojson'\n",
    "gdf_states = GeoDataFrame.from_file(geo_admin_url)\n",
    "\n",
    "#Create pySpark dataframe and view\n",
    "spark_states_df = spark.createDataFrame(gdf_states)\n",
    "spark_states_df.createOrReplaceTempView('states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0c18db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- ISO3166-1-Alpha-3: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_states_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6616ac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------+----------+--------+--------------------+\n",
      "|      name|             country|ISO3166-1-Alpha-3|state_code|      id|            geometry|\n",
      "+----------+--------------------+-----------------+----------+--------+--------------------+\n",
      "|   Alabama|United States of ...|              USA|        AL|USA-3541|POLYGON ((-85.054...|\n",
      "|    Alaska|United States of ...|              USA|        AK|USA-3563|MULTIPOLYGON (((-...|\n",
      "|   Arizona|United States of ...|              USA|        AZ|USA-3520|POLYGON ((-109.04...|\n",
      "|  Arkansas|United States of ...|              USA|        AR|USA-3528|POLYGON ((-89.662...|\n",
      "|California|United States of ...|              USA|        CA|USA-3521|POLYGON ((-114.35...|\n",
      "+----------+--------------------+-----------------+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inspect view\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM states ORDER BY name \n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ca021",
   "metadata": {},
   "source": [
    "### Create dataframe from data, localy located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eba01635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('/opt/bitnami/spark/temp/states_2022-01-03-00.csv',inferSchema =True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba4232",
   "metadata": {},
   "source": [
    "### Create UDF to transform lat/long to shapely geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3410c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def create_WKT(lat, lon):\n",
    "    wkt_point = f'POINT({lon} {lat})'\n",
    "    return wkt_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5f31a",
   "metadata": {},
   "source": [
    "### Discover data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf189c39-c4de-4fea-b9b5-4679aa315ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: integer (nullable = true)\n",
      " |-- icao24: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- velocity: double (nullable = true)\n",
      " |-- heading: double (nullable = true)\n",
      " |-- vertrate: double (nullable = true)\n",
      " |-- callsign: string (nullable = true)\n",
      " |-- onground: boolean (nullable = true)\n",
      " |-- alert: boolean (nullable = true)\n",
      " |-- spi: boolean (nullable = true)\n",
      " |-- squawk: integer (nullable = true)\n",
      " |-- baroaltitude: double (nullable = true)\n",
      " |-- geoaltitude: double (nullable = true)\n",
      " |-- lastposupdate: double (nullable = true)\n",
      " |-- lastcontact: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bdbfae",
   "metadata": {},
   "source": [
    "# A total number of flying vehicles in particular Monday.\n",
    "\n",
    "To know that we need to count unique icao24 identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49643158",
   "metadata": {},
   "outputs": [],
   "source": [
    "unicue_vehicles = df.select('icao24').distinct().count()\n",
    "print(f'Number of unique vehicles is {unicue_vehicles}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c20c85",
   "metadata": {},
   "source": [
    "### Modify DataFrame and add a column with WKT coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f62cad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(). \\\n",
    "    withColumn('geometry_wkt', create_WKT(col('lat'), col('lon'))). \\\n",
    "    createOrReplaceTempView('points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6334ac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *, ST_GeomFromWKT(geometry_wkt) as geometry FROM points\n",
    "    \"\"\"\n",
    ").createOrReplaceTempView('points_geom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1233c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+\n",
      "|icao24|     name|\n",
      "+------+---------+\n",
      "|a8df96|    Texas|\n",
      "|abb1de|    Texas|\n",
      "|a46796|  Florida|\n",
      "|a86e6c|Louisiana|\n",
      "|a70083|    Texas|\n",
      "+------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT p.icao24, s.name\n",
    "    FROM points_geom AS p, states as S\n",
    "    WHERE ST_Intersects(p.geometry, s.geometry)\n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c830f71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv36",
   "language": "python",
   "name": "venv36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d8ebf28e1eb46e34553828ab0af705a525e470337b2a6b5564f9d4d982e1a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
