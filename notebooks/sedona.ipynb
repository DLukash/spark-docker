{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "52f6becb-4246-40bc-8983-3f365121d94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "from pyspark import SparkConf, SparkFiles\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast, pandas_udf, PandasUDFType, udf, col, rank\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "from sedona.utils import KryoSerializer, SedonaKryoRegistrator\n",
    "from sedona.utils.adapter import Adapter\n",
    "from sedona.register import SedonaRegistrator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9947fa69",
   "metadata": {},
   "source": [
    "### Create SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5e2d48-598c-4652-a1e5-2938fa383063",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_DRIVER_PYTHON'] = \"/opt/conda/envs/venv36/bin/python\"\n",
    "spark = SparkSession.builder.master(\"spark://spark:7077\"). \\\n",
    "    config(\"spark.serializer\", KryoSerializer.getName). \\\n",
    "    config(\"spark.kryo.registrator\", SedonaKryoRegistrator.getName). \\\n",
    "    config('spark.jars.packages',\n",
    "           'org.apache.sedona:sedona-python-adapter-3.0_2.12:1.0.0-incubating,'\n",
    "           'org.datasyslab:geotools-wrapper:geotools-24.0'). \\\n",
    "    appName('OpenSky_app'). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0108a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add spatial functionality to the SparkSession\n",
    "SedonaRegistrator.registerAll(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f9a23",
   "metadata": {},
   "source": [
    "### Load states boundaries dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27a40ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/venv36/lib/python3.6/site-packages/geopandas/array.py:85: ShapelyDeprecationWarning: __len__ for multi-part geometries is deprecated and will be removed in Shapely 2.0. Check the length of the `geoms` property instead to get the  number of parts of a multi-part geometry.\n",
      "  aout[:] = out\n",
      "/opt/conda/envs/venv36/lib/python3.6/site-packages/geopandas/array.py:85: ShapelyDeprecationWarning: Iteration over multi-part geometries is deprecated and will be removed in Shapely 2.0. Use the `geoms` property to access the constituent parts of a multi-part geometry.\n",
      "  aout[:] = out\n"
     ]
    }
   ],
   "source": [
    "#Load data from local file to geoDataFrame\n",
    "geo_admin_url = 'admin1-us.geojson'\n",
    "gdf_states = GeoDataFrame.from_file(geo_admin_url)\n",
    "\n",
    "#Create pySpark dataframe and view\n",
    "spark_states_df = spark.createDataFrame(gdf_states)\n",
    "spark_states_df.createOrReplaceTempView('states')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f0c18db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- ISO3166-1-Alpha-3: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_states_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6616ac8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-----------------+----------+--------+--------------------+\n",
      "|      name|             country|ISO3166-1-Alpha-3|state_code|      id|            geometry|\n",
      "+----------+--------------------+-----------------+----------+--------+--------------------+\n",
      "|   Alabama|United States of ...|              USA|        AL|USA-3541|POLYGON ((-85.054...|\n",
      "|    Alaska|United States of ...|              USA|        AK|USA-3563|MULTIPOLYGON (((-...|\n",
      "|   Arizona|United States of ...|              USA|        AZ|USA-3520|POLYGON ((-109.04...|\n",
      "|  Arkansas|United States of ...|              USA|        AR|USA-3528|POLYGON ((-89.662...|\n",
      "|California|United States of ...|              USA|        CA|USA-3521|POLYGON ((-114.35...|\n",
      "+----------+--------------------+-----------------+----------+--------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inspect view\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT * FROM states ORDER BY name \n",
    "    \"\"\"\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ca021",
   "metadata": {},
   "source": [
    "### Create dataframe from data located localy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eba01635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.csv('/opt/bitnami/spark/temp/states_2022-01-03-00.csv',inferSchema =True, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feba4232",
   "metadata": {},
   "source": [
    "### Create UDF to transform lat/long to shapely geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3410c45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def create_WKT(lat, lon):\n",
    "    wkt_point = f'POINT({lon} {lat})'\n",
    "    return wkt_point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf1688",
   "metadata": {},
   "source": [
    "### Create UDF to transforn angle of heading into named direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "20f2fbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(returnType=StringType())\n",
    "def create_direction(angle):\n",
    "    if 337.5 < angle or angle < 45: return \"North\"\n",
    "    if 67.5 > angle > 22.5 : return \"Northeast\"\n",
    "    if 112.5 > angle > 67.5 : return \"East\"\n",
    "    if 157.5 > angle > 112.5 : return \"Southeast\"\n",
    "    if 202.5 > angle > 157.5 : return \"South\"\n",
    "    if 247.5 > angle > 202.5 : return \"Southwest\"\n",
    "    if 292.5 > angle > 247.5 : return \"West\"\n",
    "    if 337.5 > angle > 292.5 : return \"Northwest\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5f31a",
   "metadata": {},
   "source": [
    "### Discover data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf189c39-c4de-4fea-b9b5-4679aa315ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: integer (nullable = true)\n",
      " |-- icao24: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- velocity: double (nullable = true)\n",
      " |-- heading: double (nullable = true)\n",
      " |-- vertrate: double (nullable = true)\n",
      " |-- callsign: string (nullable = true)\n",
      " |-- onground: boolean (nullable = true)\n",
      " |-- alert: boolean (nullable = true)\n",
      " |-- spi: boolean (nullable = true)\n",
      " |-- squawk: integer (nullable = true)\n",
      " |-- baroaltitude: double (nullable = true)\n",
      " |-- geoaltitude: double (nullable = true)\n",
      " |-- lastposupdate: double (nullable = true)\n",
      " |-- lastcontact: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bdbfae",
   "metadata": {},
   "source": [
    "# A total number of flying vehicles in particular Monday.\n",
    "\n",
    "To know that we need to count unique icao24 identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49643158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique vehicles is 10508\n"
     ]
    }
   ],
   "source": [
    "unicue_vehicles = df.select('icao24').distinct().count()\n",
    "print(f'Number of unique vehicles is {unicue_vehicles}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c20c85",
   "metadata": {},
   "source": [
    "### Modify DataFrame and add a column with WKT coordinates, shapely geometry and direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f62cad76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filterout null data and vehicles ion the ground\n",
    "df.dropna(subset=(\"icao24\", \"lat\", \"lon\")). \\\n",
    "    filter(col('onground') == False). \\\n",
    "    withColumn('geometry_wkt', create_WKT(col('lat'), col('lon'))). \\\n",
    "    withColumn('heading_str', create_direction(col('heading'))). \\\n",
    "    createOrReplaceTempView('points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09abd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT *\n",
    "    FROM (SELECT *, ST_GeomFromWKT(geometry_wkt) as geometry \n",
    "            FROM points) AS p, states as S\n",
    "    WHERE ST_Intersects(p.geometry, s.geometry)\n",
    "    \"\"\"\n",
    ")\n",
    "merged_df.createOrReplaceTempView('merged_view')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7e8912fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: integer (nullable = true)\n",
      " |-- icao24: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- velocity: double (nullable = true)\n",
      " |-- heading: double (nullable = true)\n",
      " |-- vertrate: double (nullable = true)\n",
      " |-- callsign: string (nullable = true)\n",
      " |-- onground: boolean (nullable = true)\n",
      " |-- alert: boolean (nullable = true)\n",
      " |-- spi: boolean (nullable = true)\n",
      " |-- squawk: integer (nullable = true)\n",
      " |-- baroaltitude: double (nullable = true)\n",
      " |-- geoaltitude: double (nullable = true)\n",
      " |-- lastposupdate: double (nullable = true)\n",
      " |-- lastcontact: double (nullable = true)\n",
      " |-- geometry_wkt: string (nullable = true)\n",
      " |-- heading_str: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = false)\n",
      " |-- name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- ISO3166-1-Alpha-3: string (nullable = true)\n",
      " |-- state_code: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- geometry: geometry (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merged_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3441539",
   "metadata": {},
   "source": [
    "### Find top values of vertical speed, speed of ascending and descending, and the highest flight in the all US teritory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "54d92ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+--------------+------------------+\n",
      "|        nomination|icao24|         state|             value|\n",
      "+------------------+------+--------------+------------------+\n",
      "|fastest descending|a92a7c|    California|-95.91040000000001|\n",
      "| fastest ascending|a1e9a0|       Indiana|          165.8112|\n",
      "|  fastest vertival|a43ca8|       Alabama| 554.6338601488377|\n",
      "| fastest ascending|a585e4|     Louisiana|          165.8112|\n",
      "|    highest flight|a8793d|South Carolina|38221.920000000006|\n",
      "+------------------+------+--------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Faster ascending vehicle\n",
    "TOP_values_df = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT \"fastest vertival\" as nomination, icao24, name as state, mv.velocity as value\n",
    "    FROM merged_view as mv\n",
    "    INNER JOIN    \n",
    "        (SELECT max(mv) as velocity\n",
    "        FROM (SELECT icao24, max(velocity) as mv\n",
    "                FROM merged_view\n",
    "                GROUP BY icao24) as mv) as mx\n",
    "                ON mv.velocity = mx.velocity\n",
    "    UNION\n",
    "    SELECT DISTINCT \"fastest ascending\" as nomination, icao24, name as state, mv.vertrate as value\n",
    "    FROM merged_view as mv\n",
    "    INNER JOIN    \n",
    "        (SELECT max(mv) as vertrate\n",
    "        FROM (SELECT icao24, max(vertrate) as mv\n",
    "                FROM merged_view\n",
    "                GROUP BY icao24) as mv) as mx\n",
    "                ON mv.vertrate = mx.vertrate\n",
    "    UNION\n",
    "    SELECT DISTINCT \"fastest descending\" as nomination, icao24, name as state, mv.vertrate as value\n",
    "    FROM merged_view as mv\n",
    "    INNER JOIN    \n",
    "        (SELECT min(mv) as vertrate\n",
    "        FROM (SELECT icao24, min(vertrate) as mv\n",
    "                FROM merged_view\n",
    "                GROUP BY icao24) as mv) as mx\n",
    "                ON mv.vertrate = mx.vertrate\n",
    "    UNION\n",
    "    SELECT DISTINCT \"highest flight\" as nomination, icao24, name as state, mv.geoaltitude as value\n",
    "    FROM merged_view as mv\n",
    "    INNER JOIN    \n",
    "        (SELECT max(geoalt) as geoalt\n",
    "        FROM (SELECT icao24, max(geoaltitude) as geoalt\n",
    "                FROM merged_view\n",
    "                GROUP BY icao24) as mv) as mx\n",
    "                ON mv.geoaltitude = mx.geoalt\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "TOP_values_df.write.csv('TOP_values.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb91fa",
   "metadata": {},
   "source": [
    "### Find the most common side of the world as direction of flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "00396fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+\n",
      "|heading_str|quantity|\n",
      "+-----------+--------+\n",
      "|       West|  240066|\n",
      "|      North|  204990|\n",
      "|       East|  185085|\n",
      "|  Northwest|  151408|\n",
      "|  Southwest|  127541|\n",
      "|      South|  123995|\n",
      "|  Southeast|  109286|\n",
      "|  Northeast|   68357|\n",
      "+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The most common direction\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT heading_str, count (*) as quantity\n",
    "    FROM merged_view\n",
    "    WHERE heading_str IS NOT NULL\n",
    "    GROUP BY heading_str\n",
    "    ORDER BY quantity DESC\n",
    "    \"\"\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014c6a0",
   "metadata": {},
   "source": [
    "### Find top values of vertical speed, speed of ascending and descending, and the highest flight in each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a29ca6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fastest vehicle\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT \"fastest vertival\" as nomination, name as state, icao24,  mv.velocity as value\n",
    "    FROM merged_view as mv\n",
    "    INNER JOIN    \n",
    "        (SELECT state, max(mv) as velocity\n",
    "        FROM (SELECT name as state, icao24, max(velocity) as mv\n",
    "                FROM merged_view\n",
    "                GROUP BY name, icao24) as mv\n",
    "        GROUP BY state) as mx\n",
    "    ON mv.velocity = mx.velocity and mv.name = mx.state\n",
    "    \"\"\"\n",
    ").createOrReplaceTempView('fastest_State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aaea3b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fastest ascending\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT \"fastest ascending\" as nomination, name as state, icao24,  mv.vertrate as value\n",
    "        FROM merged_view as mv\n",
    "        INNER JOIN    \n",
    "            (SELECT state, max(mv) as vertrate\n",
    "            FROM (SELECT name as state, icao24, max(vertrate) as mv\n",
    "                    FROM merged_view\n",
    "                    GROUP BY name, icao24) as mv\n",
    "            GROUP BY state) as mx\n",
    "        ON mv.vertrate = mx.vertrate and mv.name = mx.state\n",
    "    \"\"\"\n",
    ").createOrReplaceTempView('fastest_ASC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b25f9c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fastest descending\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT DISTINCT \"fastest ascending\" as nomination, name as state, icao24,  mv.vertrate as value\n",
    "        FROM merged_view as mv\n",
    "        INNER JOIN    \n",
    "            (SELECT state, min(mv) as vertrate\n",
    "            FROM (SELECT name as state, icao24, min(vertrate) as mv\n",
    "                    FROM merged_view\n",
    "                    GROUP BY name, icao24) as mv\n",
    "            GROUP BY state) as mx\n",
    "        ON mv.vertrate = mx.vertrate and mv.name = mx.state\n",
    "    \"\"\"\n",
    ").createOrReplaceTempView('fastest_DESC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1828ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Highest flight\n",
    "spark.sql(\n",
    "    \"\"\"    \n",
    "    SELECT DISTINCT \"highest flight\" as nomination, name as state, icao24, mv.geoaltitude as value\n",
    "    FROM merged_view as mv\n",
    "    INNER JOIN    \n",
    "        (SELECT state, max(geoalt) as geoalt\n",
    "        FROM (SELECT name as state, icao24, max(geoaltitude) as geoalt\n",
    "                FROM merged_view\n",
    "                GROUP BY name, icao24) as mv\n",
    "        GROUP BY state) as mx\n",
    "                ON mv.geoaltitude = mx.geoalt and mv.name = mx.state\n",
    "    \"\"\"\n",
    ").createOrReplaceTempView('highest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ba4bbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_result_df = spark.sql(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "      fa.state, \n",
    "      fa.highest_altitude, \n",
    "      fa.highest_plane, \n",
    "      fa.fastest_desc, \n",
    "      fa.fastest_dc_plain, \n",
    "      fa.fastest_asc, \n",
    "      fa.fastest_asc_pain, \n",
    "      fs.value as highest_velocity, \n",
    "      fs.icao24 as fastest_plain \n",
    "    FROM \n",
    "      (\n",
    "        SELECT \n",
    "          fd.state, \n",
    "          fd.highest_altitude, \n",
    "          fd.highest_plane, \n",
    "          fd.fastest_desc, \n",
    "          fd.fastest_dc_plain, \n",
    "          fa.value as fastest_asc, \n",
    "          fa.icao24 as fastest_asc_pain \n",
    "          FROM\n",
    "              (\n",
    "            SELECT \n",
    "              h.state as state, \n",
    "              h.highest_altitude, \n",
    "              h.highest_plane, \n",
    "              fd.value as fastest_desc, \n",
    "              fd.icao24 as fastest_dc_plain \n",
    "            FROM \n",
    "              (\n",
    "                SELECT \n",
    "                  s.name as state, \n",
    "                  h.value as highest_altitude, \n",
    "                  h.icao24 as highest_plane \n",
    "                FROM \n",
    "                  states as s \n",
    "                  LEFT JOIN highest as h ON h.state = s.name \n",
    "                ORDER BY \n",
    "                  s.name\n",
    "              ) as h \n",
    "              LEFT JOIN fastest_DESC as fd ON h.state = fd.state\n",
    "          ) as fd \n",
    "          LEFT JOIN fastest_ASC as fa ON fd.state = fa.state\n",
    "      ) as fa \n",
    "      LEFT JOIN fastest_State as fs ON fa.state = fs.state\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "#Store results as csv\n",
    "state_result_df.write.csv('TOP_values_by_states.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d26cb7",
   "metadata": {},
   "source": [
    "### Find the most common direction by each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7f246a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|               state|heading_Str|\n",
      "+--------------------+-----------+\n",
      "|                Utah|  Northeast|\n",
      "|           Minnesota|      South|\n",
      "|                Ohio|  Southwest|\n",
      "|            Arkansas|      South|\n",
      "|              Oregon|  Northeast|\n",
      "|               Texas|  Northeast|\n",
      "|        North Dakota|  Northeast|\n",
      "|        Pennsylvania|  Northeast|\n",
      "|         Connecticut|  Southeast|\n",
      "|            Nebraska|      North|\n",
      "|             Vermont|      South|\n",
      "|              Nevada|  Northeast|\n",
      "|          Washington|  Northeast|\n",
      "|            Illinois|  Northeast|\n",
      "|            Oklahoma|  Northeast|\n",
      "|District of Columbia|  Southeast|\n",
      "|            Delaware|  Northwest|\n",
      "|              Alaska|  Southeast|\n",
      "|          New Mexico|      South|\n",
      "|       West Virginia|  Southeast|\n",
      "+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The most common direction\n",
    "windowSpec = Window.partitionBy(\"state\").orderBy(\"quantity\")\n",
    "\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "        SELECT name as state, heading_str, count (*) as quantity\n",
    "            FROM merged_view\n",
    "            WHERE heading_str IS NOT NULL\n",
    "            GROUP BY heading_str, name\n",
    "            ORDER BY quantity DESC\n",
    "    \"\"\"\n",
    ").withColumn(\"rank\",rank().over(windowSpec)). \\\n",
    "    filter(col('rank') == 1). \\\n",
    "    select('state', 'heading_Str'). \\\n",
    "    show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9d8ebf28e1eb46e34553828ab0af705a525e470337b2a6b5564f9d4d982e1a6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
